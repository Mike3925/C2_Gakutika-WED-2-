{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93651bae-9c72-4653-b4ed-38210f7a8cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- データの先頭 ---\n",
      "   id                                               text  label\n",
      "0   1  登坂 車線 ある 高速 自動 車 国道 大型 貨物 自動 車 必ず 登坂 車線 通行 し な...      0\n",
      "1   2  前方 自転 車 追い越そう し た 左右 ふらつい おり 危険 予測 さ れ た で 危険 ...      1\n",
      "2   3                       バス 運転 手 乗客 少なけれ 乗客 世間 話 し よい      0\n",
      "3   4  路線 バス 運転 者 運転 中 ドア 故障 し 閉まら なく なっ た 乗客 少なかっ た ...      0\n",
      "4   5  路線 バス 運転 者 客 乗り降り ため 停止 中 窓 手 出し いる 乗客 い た で 注...      1\n",
      "\n",
      "--- ラベルの分布 ---\n",
      "label\n",
      "0    389\n",
      "1    318\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "df = pd.read_csv('../data/data.csv')\n",
    "\n",
    "# データの内容を先頭5行表示して確認\n",
    "print(\"--- データの先頭 ---\")\n",
    "print(df.head())\n",
    "\n",
    "# データ件数と、ラベルの分布を確認（0と1が何件ずつあるか）\n",
    "print(\"\\n--- ラベルの分布 ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# テキストデータとラベルをそれぞれ変数に格納\n",
    "X_text = df['text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113c4137-5646-435e-8bc9-e6185b640a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ベクトル化後のデータ形状 ---\n",
      "(707, 1290)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TfidfVectorizerを初期化\n",
    "# analyzer='word' は単語単位で処理することを意味します（今回は既に分かち書き済なのでデフォルトでOK）\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# テキストデータ (X_text) をTF-IDFベクトルに変換\n",
    "X_vec = vectorizer.fit_transform(X_text)\n",
    "\n",
    "# 変換後のデータの形状を確認\n",
    "# (文書数, ユニークな単語数) の形式になっている\n",
    "print(\"\\n--- ベクトル化後のデータ形状 ---\")\n",
    "print(X_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ce9221-8538-4c69-9d76-18ced788ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 分割後のデータサイズ ---\n",
      "訓練データ: 565件\n",
      "テストデータ: 142件\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ベクトル化したデータとラベルを、訓練データとテストデータに分割\n",
    "# test_size=0.2 は、20%をテストデータに使うという意味\n",
    "# stratify=y は、分割後の訓練/テストデータでラベルの比率が元データと同じになるようにするオプション\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n--- 分割後のデータサイズ ---\")\n",
    "print(f\"訓練データ: {X_train.shape[0]}件\")\n",
    "print(f\"テストデータ: {X_test.shape[0]}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da08c29-a9ff-4d5a-942b-641d7aa026a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- モデルの学習が完了しました ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ロジスティック回帰モデルを初期化\n",
    "model = LogisticRegression()\n",
    "\n",
    "# モデルを訓練データで学習させる\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- モデルの学習が完了しました ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade52475-511e-4105-b382-6d6ee61028d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正解率 (Accuracy): 0.6549\n",
      "\n",
      "--- 分類レポート (Classification Report) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.73        78\n",
      "           1       0.70      0.41      0.51        64\n",
      "\n",
      "    accuracy                           0.65       142\n",
      "   macro avg       0.67      0.63      0.62       142\n",
      "weighted avg       0.67      0.65      0.63       142\n",
      "\n",
      "\n",
      "--- 混合行列 (Confusion Matrix) ---\n",
      "[[67 11]\n",
      " [38 26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# テストデータを使って予測を行う\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 1. 正解率 (Accuracy) の計算\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n正解率 (Accuracy): {accuracy:.4f}\")\n",
    "\n",
    "# 2. 適合率、再現率、F1スコアの表示\n",
    "# これらは、特にラベルの分布に偏りがある場合に重要な指標\n",
    "print(\"\\n--- 分類レポート (Classification Report) ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 3. 混合行列 (Confusion Matrix) の表示\n",
    "# どのような間違い方をしたかが分かる\n",
    "print(\"\\n--- 混合行列 (Confusion Matrix) ---\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c981a551-c7b2-4ad4-ad98-79b5bdfd29ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カーブ 走行 する 時 速度 ２ 倍 なる 遠心 力 ４ 倍 なる\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'カーブを走行する時、速度が２倍になると遠心力は４倍になる 。',\n",
       " 'wakati': 'カーブ 走行 する 時 速度 ２ 倍 なる 遠心 力 ４ 倍 なる',\n",
       " 'predicted_label': 1,\n",
       " 'probability_0': 0.43805042916687686,\n",
       " 'probability_1': 0.5619495708331231}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugashi\n",
    "\n",
    "sentence = \"二輪車でカーブをまがる時は、遠心力に対抗するため車体を外側に傾けてまがるようにする 。\"\n",
    "\n",
    "def wakatiSentence(sentense):\n",
    "    tagger = fugashi.Tagger()\n",
    "    # nouns = [word.feature.lemma for word in tagger(sentense) if (word.feature.pos1 != \"助詞\" and word.feature.pos1 != \"補助記号\")]\n",
    "    nouns = [word.surface for word in tagger(sentense) if (word.feature.pos1 != \"助詞\" and word.feature.pos1 != \"補助記号\")]\n",
    "    # print(tagger(sentense))\n",
    "    # print(\"--- 名詞リスト ---\")\n",
    "    # print(nouns)\n",
    "    out = \"\"\n",
    "    for i in range(len(nouns)):\n",
    "        if (i == len(nouns) - 1):\n",
    "          out = out + nouns[i]\n",
    "        else:\n",
    "          out = out + nouns[i] + \" \"\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "# 前のステップで学習済みの model と vectorizer が存在すると仮定します。\n",
    "# (このコードの前に、前回の学習コードが実行されている状態です)\n",
    "\n",
    "def predict_text(text: str):\n",
    "    \"\"\"\n",
    "    新しいテキストを受け取り、前処理から予測までを行って結果を返す関数\n",
    "    \"\"\"\n",
    "    # ステップ1: 新しい文章を分かち書きする\n",
    "    # tagger.parse() は最後に改行が入るので .strip() する\n",
    "    wakati_text = wakatiSentence(text)\n",
    "    \n",
    "    # ステップ2: 学習済みvectorizerでベクトル化する\n",
    "    # .transform() はリストや配列を期待するため、文字列をリストに入れる\n",
    "    text_vector = vectorizer.transform([wakati_text])\n",
    "    \n",
    "    # ステップ3: 学習済みモデルで予測する\n",
    "    # .predict() はラベル（[0]や[1]）を返す\n",
    "    predicted_label = model.predict(text_vector)\n",
    "    \n",
    "    # .predict_proba() は各ラベルに属する確率（[[0.1, 0.9]]など）を返す\n",
    "    predicted_proba = model.predict_proba(text_vector)\n",
    "    \n",
    "    # 結果を分かりやすく辞書形式で返す\n",
    "    result = {\n",
    "        \"text\": text,\n",
    "        \"wakati\": wakati_text,\n",
    "        \"predicted_label\": predicted_label[0], # 配列から値を取り出す\n",
    "        \"probability_0\": predicted_proba[0][0], # ラベル0の確率\n",
    "        \"probability_1\": predicted_proba[0][1]  # ラベル1の確率\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "predict_text(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
